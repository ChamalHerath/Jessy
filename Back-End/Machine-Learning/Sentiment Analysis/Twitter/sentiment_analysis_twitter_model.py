# -*- coding: utf-8 -*-
"""sentiment analysis twitter model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14xTHda6svzxHtYAJajhJwzf4ucH9bQy2
"""

#sentimate analysis for the social media data

#import libraries
import tweepy
from textblob import TextBlob
from wordcloud import WordCloud
import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

#load data
from google.colab import files
uploaded = files.upload()

#get the data from the account
log = pd.read_csv('key.csv')

#twitter API Credentials
apiKey = log['apiKey'][0]
apiSecret = log['apiSecret'][0]
accessToken = log['accessToken'][0]
accessTokenScret = log['accessTokenScret'][0]

#authentication object
authenticate = tweepy.OAuthHandler(apiKey, apiSecret)

#set the acess token and acess token secret
authenticate.set_access_token(accessToken, accessTokenScret)

#Create the API object while passing in the authentication information
api = tweepy.API(authenticate, wait_on_rate_limit=True)

#Extract 100 tweets from the twitter user
posts = api.user_timeline(screen_name='@BillGates', count=100, lang = "en", tweet_mode="extended")

#show the last few tweets
print("Show recent tweets\n")
i=0
for tweet in posts[0:5]:
  print(str(i) + ') '+ tweet.full_text + '\n')
  i = i+1

#create a dataframe with tweets
df = pd.DataFrame([tweet.full_text for tweet in posts], columns=['Tweets'])

#show recent ones
df.head()

#clean the text

#function to clean the tweets
def cleanText(text):
  text = re.sub(r'@[A-Za-z0-9]+', '', text)
  text = re.sub(r'#', '', text)
  text = re.sub(r'RT[\s]', '', text)
  text = re.sub(r'https?:\/\/\S+', '', text)

  return text

df['Tweets']=df['Tweets'].apply(cleanText)
df

#get the subjectivity
def getSubjectivity(text):
  return TextBlob(text).sentiment.subjectivity

#get the polarity
def getPolarity(text):
  return TextBlob(text).sentiment.polarity

#creating the columns
df['Subjectivity'] = df['Tweets'].apply(getSubjectivity)
df['Polarity'] = df['Tweets'].apply(getPolarity)

df

#word cloud
allWords = ' '.join( [twts for twts in df['Tweets']] )
wordCloud = WordCloud(width=500, height=300, random_state = 21, max_font_size = 119).generate(allWords)

plt.imshow(wordCloud, interpolation="bilinear")
#plt.access('off')
plt.show()

#create a function to compute the world weight analysis
def getAnalysis(score):
  if score<0:
    return 'Negative'
  elif score == 0:
    return 'Neutral'
  else:
    return 'Positive'

df['Analysis']=df['Polarity'].apply(getAnalysis)

#show the data Frame
df

#print all of the positive tweets
j=1
sortedDF = df.sort_values(by=['Polarity'])
for i in range(0, sortedDF.shape[0]):
  if (sortedDF['Analysis'][i]=='Positve'):
    print(str(j) + ') ' + sortedDF['Tweets'][i])
    print()
    j = j+1

#print all the negative tweets
j=1
sortedDF = df.sort_values(by=['Polarity'], ascending='False')
for i in range(0, sortedDF.shape[0]):
  if (sortedDF['Analysis'][i]=='Negative'):
    print(str(j) + ') ' + sortedDF['Tweets'][i])
    print()
    j = j+1

#plot the values
plt.figure(figsize=(8,6))
for i in range (0, df.shape[0]):
  plt.scatter(df['Polarity'][i], df['Subjectivity'][i], color='Blue')

plt.title('Sentiment Analysis')
plt.xlabel('Polarity')
plt.ylabel('Subjectivity')
plt.show()

#show the final data values
df['Analysis'].value_counts()

#plot the values
plt.title('Sentiment Analysis')
plt.xlabel('Sentiment')
plt.ylabel('Count')
df['Analysis'].value_counts().plot(kind='bar')
plt.show()